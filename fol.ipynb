{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from collections import Counter\n",
    "from pyDatalog import pyDatalog as plog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_Id</th>\n",
       "      <th>Product Name</th>\n",
       "      <th>minprice</th>\n",
       "      <th>maxprice</th>\n",
       "      <th>Description</th>\n",
       "      <th>Categories</th>\n",
       "      <th>Image</th>\n",
       "      <th>Tags List</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Haier 32 Inches 4K QLED Google TV H32S80EFX</td>\n",
       "      <td>48000</td>\n",
       "      <td>53000</td>\n",
       "      <td>The Haier 32S80EFX is a 32-inch Smart QLED LED...</td>\n",
       "      <td>Small Electronics,LEDs &amp; Audio</td>\n",
       "      <td>Haier_32_Inches_4K_QLED_Google_TV_H32S80EFX.jpg</td>\n",
       "      <td>Energy-efficient,Smart,Bluetooth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Haier 40 Inch FHD Android LED TV 40K800FX</td>\n",
       "      <td>64999</td>\n",
       "      <td>74999</td>\n",
       "      <td>The 40-inch Full HD Smart TV features Google T...</td>\n",
       "      <td>Small Electronics,LEDs &amp; Audio</td>\n",
       "      <td>Haier_40_Inch_FHD_Android_LED_TV_40K800FX.jpg</td>\n",
       "      <td>LED,Energy-efficient,Bluetooth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Haier 40 Inches 4K FHD Google TV H40K800FXS</td>\n",
       "      <td>69899</td>\n",
       "      <td>78999</td>\n",
       "      <td>The Haier H40K800FX is a Full HD Smart Google ...</td>\n",
       "      <td>Small Electronics,LEDs &amp; Audio</td>\n",
       "      <td>Haier_40_Inches_4K_FHD_Google_TV_H40K800FXS.jpg</td>\n",
       "      <td>Smart,Wi-Fi,Connectivity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Haier 43 Inches 4K Google QLED TV 43S800UX</td>\n",
       "      <td>90000</td>\n",
       "      <td>95000</td>\n",
       "      <td>Buy Haier 43 Inches 4K Google QLED TV 43S800UX...</td>\n",
       "      <td>Small Electronics,LEDs &amp; Audio</td>\n",
       "      <td>Haier_43_Inches_4K_Google_QLED_TV_43S800UX.jpg</td>\n",
       "      <td>Sound,Bluetooth,LED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Haier 50 Inches 4K Google QLED TV 50S800UX</td>\n",
       "      <td>127500</td>\n",
       "      <td>130750</td>\n",
       "      <td>Buy Haier 50 Inches 4K Google QLED TV 50S800UX...</td>\n",
       "      <td>Small Electronics,LEDs &amp; Audio</td>\n",
       "      <td>Haier_50_Inches_4K_Google_QLED_TV_50S800UX.jpg</td>\n",
       "      <td>Smart,Audio,Energy-efficient</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Product_Id                                 Product Name  minprice  \\\n",
       "0           1  Haier 32 Inches 4K QLED Google TV H32S80EFX     48000   \n",
       "1           2    Haier 40 Inch FHD Android LED TV 40K800FX     64999   \n",
       "2           3  Haier 40 Inches 4K FHD Google TV H40K800FXS     69899   \n",
       "3           4   Haier 43 Inches 4K Google QLED TV 43S800UX     90000   \n",
       "4           5   Haier 50 Inches 4K Google QLED TV 50S800UX    127500   \n",
       "\n",
       "   maxprice                                        Description  \\\n",
       "0     53000  The Haier 32S80EFX is a 32-inch Smart QLED LED...   \n",
       "1     74999  The 40-inch Full HD Smart TV features Google T...   \n",
       "2     78999  The Haier H40K800FX is a Full HD Smart Google ...   \n",
       "3     95000  Buy Haier 43 Inches 4K Google QLED TV 43S800UX...   \n",
       "4    130750  Buy Haier 50 Inches 4K Google QLED TV 50S800UX...   \n",
       "\n",
       "                       Categories  \\\n",
       "0  Small Electronics,LEDs & Audio   \n",
       "1  Small Electronics,LEDs & Audio   \n",
       "2  Small Electronics,LEDs & Audio   \n",
       "3  Small Electronics,LEDs & Audio   \n",
       "4  Small Electronics,LEDs & Audio   \n",
       "\n",
       "                                             Image  \\\n",
       "0  Haier_32_Inches_4K_QLED_Google_TV_H32S80EFX.jpg   \n",
       "1    Haier_40_Inch_FHD_Android_LED_TV_40K800FX.jpg   \n",
       "2  Haier_40_Inches_4K_FHD_Google_TV_H40K800FXS.jpg   \n",
       "3   Haier_43_Inches_4K_Google_QLED_TV_43S800UX.jpg   \n",
       "4   Haier_50_Inches_4K_Google_QLED_TV_50S800UX.jpg   \n",
       "\n",
       "                          Tags List  \n",
       "0  Energy-efficient,Smart,Bluetooth  \n",
       "1    LED,Energy-efficient,Bluetooth  \n",
       "2          Smart,Wi-Fi,Connectivity  \n",
       "3               Sound,Bluetooth,LED  \n",
       "4      Smart,Audio,Energy-efficient  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plog.clear()\n",
    "df = pd.read_csv('All_Products_Data.csv')\n",
    "df[\"Product_Id\"] = range(1 , len(df)+1)\n",
    "df.insert(0, \"Product_Id\", df.pop(\"Product_Id\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "plog.create_terms('SimilarCategory, SimilarTag , X , Y , P, Z , C , T , Product,Lies,upper_bound,lower_bound, HasPrice, User, HasCategory, HasTag, LikedByUser, Recommended , min_price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Product_Id', 'Product Name', 'minprice', 'maxprice', 'Description',\n",
       "       'Categories', 'Image', 'Tags List'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addFacts(user_data,df):\n",
    "    # Facts for Products\n",
    "    for index, row in df.iterrows():\n",
    "\n",
    "        id = row['Product_Id']\n",
    "        name = row['Product Name']\n",
    "        min_price = row['minprice']\n",
    "        max_price = row['maxprice']\n",
    "        Categories = row['Categories']\n",
    "        Categories = Categories.split(',')\n",
    "        Tags = row[\"Tags List\"]\n",
    "        Tags = Tags.split(',')\n",
    "        # print(Categories)\n",
    "        +Product(id,name)\n",
    "        +HasPrice(id,min_price)\n",
    "\n",
    "        for category in Categories:\n",
    "            +HasCategory(id,category)\n",
    "\n",
    "        for tag in Tags:\n",
    "            +HasTag(id , tag)\n",
    "        \n",
    "    #  For users, you can define likes using LikedByUser\n",
    "    for index,row in user_data.iterrows():\n",
    "        prod_num = row['prod_id']\n",
    "        user_id = row['user_id']\n",
    "        +LikedByUser(user_id, prod_num)\n",
    "\n",
    "\n",
    "# Sample data to insert into the DataFrame\n",
    "data = {\n",
    "    'user_id': [1, 1, 2, 3, 3],\n",
    "    'prod_id': [1, 14, 19, 42, 15]\n",
    "    \n",
    "}\n",
    "\n",
    "user_data = pd.DataFrame(data)\n",
    "addFacts(user_data , df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SimilarPrice(base_price):\n",
    "    lower_bound = base_price * 0.8  # 20% less than base price\n",
    "    upper_bound = base_price * 1.2  # 20% more than base price\n",
    "\n",
    "    return plog.ask(f'Lies(X, P , {lower_bound} , {upper_bound})')\n",
    "\n",
    "# result = get_price_range_products(20000)\n",
    "# result.answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lies(X,P,'lower_bound','upper_bound') <= HasPrice("
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "SimilarCategory(X , Y , Z) <= (LikedByUser(Z, X) & HasCategory(X, C) & HasCategory(Y, C) & (X != Y))\n",
    "SimilarTag(X, Y , Z) <= (LikedByUser(Z, X) & HasTag(X, T)  & HasTag(Y, T) & (X != Y))\n",
    "Lies(X, P , lower_bound , upper_bound) <= HasPrice(X , P) & (P > lower_bound) & (P < upper_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SimilarCategoryMethod(user_id, product_id):\n",
    "    return plog.ask(f'SimilarCategory({product_id}, Y, {user_id})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SimilarTagMethod(user_id, product_id):\n",
    "    return plog.ask(f'SimilarTag({product_id}, Y, {user_id})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plog.create_terms('Count') \n",
    "# SimilarCategory(X, Y, Z, C) <= (LikedByUser(Z, X) & HasCategory(X, C) & HasCategory(Y, C) & (X != Y))\n",
    "# plog.ask(f'SimilarCategory({19}, Y , {1} , C)').answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(HasCategory(1, C) & HasCategory(2, C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plog.ask(f'SimilarCategory({41}, Y , {1} , C)')\n",
    "# SimilarCategory(41 , Y , 1 , C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HasPrice(1 , Y)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_products(user_id, top_n=10) :\n",
    "\n",
    "    liked_products = plog.ask(f'LikedByUser({user_id}, Y)')\n",
    "    product_similarity_dict = {}\n",
    "    for product in liked_products.answers:\n",
    "        prod_id = product[0]\n",
    "        similar_product = SimilarCategoryMethod(user_id , prod_id) # plog.ask(f'SimilarCategory({prod_id}, Y , {user_id})')\n",
    "        if similar_product is not None:\n",
    "            for p in similar_product.answers:\n",
    "                product_id = p[0]\n",
    "                if product_id in product_similarity_dict:\n",
    "                    product_similarity_dict[product_id] += (len(HasCategory(prod_id, C) & HasCategory(product_id, C))*10)\n",
    "                else:\n",
    "                    product_similarity_dict[product_id] = (len(HasCategory(prod_id, C) & HasCategory(product_id, C))*10)\n",
    "        similar_product = None\n",
    "        similar_product = SimilarTagMethod(prod_id , user_id) # plog.ask(f'SimilarTag({prod_id}, Y , {user_id})')\n",
    "        if similar_product is not None:\n",
    "            for p in similar_product.answers:\n",
    "                product_id = p[0]\n",
    "                if product_id in product_similarity_dict:\n",
    "                    product_similarity_dict[product_id] += (len(HasTag(prod_id, C) & HasTag(product_id, C))*5)\n",
    "                else:\n",
    "                    product_similarity_dict[product_id] = ((len(HasTag(prod_id, C) & HasTag(product_id, C))*5))\n",
    "        similar_product = None\n",
    "        base_price = HasPrice(1 , Y)[0][0] \n",
    "        similar_product = SimilarPrice(base_price)\n",
    "        if similar_product is not None:\n",
    "            for p in similar_product.answers:\n",
    "                product_id = p[0]\n",
    "                if product_id in product_similarity_dict:\n",
    "                    product_similarity_dict[product_id] += 3\n",
    "                else:\n",
    "                    product_similarity_dict[product_id] = 3\n",
    "    list_of_tuples = list(product_similarity_dict.items())\n",
    "    sorted_list = sorted(list_of_tuples, key=lambda x: x[1], reverse=True)\n",
    "    print(sorted_list)\n",
    "    new_list = [x[0] for x in sorted_list[:top_n]]\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Miniconda\\envs\\GenerativeAI\\lib\\site-packages\\IPython\\core\\formatters.py:708\u001b[0m, in \u001b[0;36mPlainTextFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    701\u001b[0m stream \u001b[38;5;241m=\u001b[39m StringIO()\n\u001b[0;32m    702\u001b[0m printer \u001b[38;5;241m=\u001b[39m pretty\u001b[38;5;241m.\u001b[39mRepresentationPrinter(stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnewline,\n\u001b[0;32m    704\u001b[0m     max_seq_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_seq_length,\n\u001b[0;32m    705\u001b[0m     singleton_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msingleton_printers,\n\u001b[0;32m    706\u001b[0m     type_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_printers,\n\u001b[0;32m    707\u001b[0m     deferred_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeferred_printers)\n\u001b[1;32m--> 708\u001b[0m \u001b[43mprinter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m printer\u001b[38;5;241m.\u001b[39mflush()\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stream\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\GenerativeAI\\lib\\site-packages\\IPython\\lib\\pretty.py:410\u001b[0m, in \u001b[0;36mRepresentationPrinter.pretty\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    407\u001b[0m                         \u001b[38;5;28;01mreturn\u001b[39;00m meth(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[0;32m    408\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mobject\u001b[39m \\\n\u001b[0;32m    409\u001b[0m                         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__repr__\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[1;32m--> 410\u001b[0m                     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_repr_pprint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcycle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_pprint(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\GenerativeAI\\lib\\site-packages\\IPython\\lib\\pretty.py:778\u001b[0m, in \u001b[0;36m_repr_pprint\u001b[1;34m(obj, p, cycle)\u001b[0m\n\u001b[0;32m    776\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[39;00m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;66;03m# Find newlines and replace them with p.break_()\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mrepr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    779\u001b[0m lines \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39msplitlines()\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgroup():\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\GenerativeAI\\lib\\site-packages\\pyDatalog\\UserList.py:16\u001b[0m, in \u001b[0;36mUserList.__repr__\u001b[1;34m(self)\u001b[0m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__repr__\u001b[39m(\u001b[38;5;28mself\u001b[39m): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m)\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\GenerativeAI\\lib\\site-packages\\pyDatalog\\pyParser.py:93\u001b[0m, in \u001b[0;36mLazyList.data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtodo \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtodo\u001b[38;5;241m.\u001b[39m_variables()\u001b[38;5;241m.\u001b[39mkeys()) \n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtodo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\GenerativeAI\\lib\\site-packages\\pyDatalog\\pyParser.py:577\u001b[0m, in \u001b[0;36mQuery.ask\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mask\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 577\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data \u001b[38;5;241m=\u001b[39m \u001b[43mBody\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_calculations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtodo \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    579\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\GenerativeAI\\lib\\site-packages\\pyDatalog\\pyParser.py:693\u001b[0m, in \u001b[0;36mBody.ask\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" resolve the query and determine the values of its variables\"\"\"\u001b[39;00m\n\u001b[0;32m    692\u001b[0m literal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mliteral()\n\u001b[1;32m--> 693\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data \u001b[38;5;241m=\u001b[39m \u001b[43mliteral\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlua\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    694\u001b[0m literal\u001b[38;5;241m.\u001b[39mtodo, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtodo \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    695\u001b[0m \u001b[38;5;241m-\u001b[39m (literal \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m) \u001b[38;5;66;03m# delete the temporary clause\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\GenerativeAI\\lib\\site-packages\\pyDatalog\\pyEngine.py:513\u001b[0m, in \u001b[0;36mpyDatalog.pyEngine.Literal.ask\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\GenerativeAI\\lib\\site-packages\\pyDatalog\\pyEngine.py:756\u001b[0m, in \u001b[0;36mpyDatalog.pyEngine.Subgoal.search\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\GenerativeAI\\lib\\site-packages\\pyDatalog\\pyEngine.py:476\u001b[0m, in \u001b[0;36mpyDatalog.pyEngine.Literal.unify\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\GenerativeAI\\lib\\site-packages\\pyDatalog\\pyEngine.py:482\u001b[0m, in \u001b[0;36mpyDatalog.pyEngine.Literal.unify\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "ls = LikedByUser(1 , Y)\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[125], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m user_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m----> 2\u001b[0m products \u001b[38;5;241m=\u001b[39m \u001b[43mrecommend_products\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m ys \u001b[38;5;241m=\u001b[39m ClickedByUser(user_id , Y)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(ys)\n",
      "Cell \u001b[1;32mIn[124], line 3\u001b[0m, in \u001b[0;36mrecommend_products\u001b[1;34m(user_id, top_n)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecommend_products\u001b[39m(user_id, top_n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m----> 3\u001b[0m     liked_products \u001b[38;5;241m=\u001b[39m \u001b[43mplog\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mask\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLikedByUser(\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43muser_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m, Y)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     product_similarity_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m product \u001b[38;5;129;01min\u001b[39;00m liked_products\u001b[38;5;241m.\u001b[39manswers:\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\GenerativeAI\\lib\\site-packages\\pyDatalog\\pyDatalog.py:111\u001b[0m, in \u001b[0;36mask\u001b[1;34m(code)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mask\u001b[39m(code):\n\u001b[0;32m    110\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"returns the result of the query contained in the code string\"\"\"\u001b[39;00m\n\u001b[1;32m--> 111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpyParser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\GenerativeAI\\lib\\site-packages\\pyDatalog\\pyParser.py:841\u001b[0m, in \u001b[0;36mask\u001b[1;34m(code)\u001b[0m\n\u001b[0;32m    839\u001b[0m add_symbols(code\u001b[38;5;241m.\u001b[39mco_names, newglobals)\n\u001b[0;32m    840\u001b[0m parsed_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(code, newglobals)\n\u001b[1;32m--> 841\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mparsed_code\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    842\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Answer\u001b[38;5;241m.\u001b[39mmake(a)\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\GenerativeAI\\lib\\site-packages\\pyDatalog\\pyParser.py:577\u001b[0m, in \u001b[0;36mQuery.ask\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mask\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 577\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data \u001b[38;5;241m=\u001b[39m \u001b[43mBody\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_calculations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtodo \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    579\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\GenerativeAI\\lib\\site-packages\\pyDatalog\\pyParser.py:693\u001b[0m, in \u001b[0;36mBody.ask\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    691\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" resolve the query and determine the values of its variables\"\"\"\u001b[39;00m\n\u001b[0;32m    692\u001b[0m literal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mliteral()\n\u001b[1;32m--> 693\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data \u001b[38;5;241m=\u001b[39m \u001b[43mliteral\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlua\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    694\u001b[0m literal\u001b[38;5;241m.\u001b[39mtodo, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtodo \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    695\u001b[0m \u001b[38;5;241m-\u001b[39m (literal \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m) \u001b[38;5;66;03m# delete the temporary clause\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\GenerativeAI\\lib\\site-packages\\pyDatalog\\pyEngine.py:513\u001b[0m, in \u001b[0;36mpyDatalog.pyEngine.Literal.ask\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\GenerativeAI\\lib\\site-packages\\pyDatalog\\pyEngine.py:756\u001b[0m, in \u001b[0;36mpyDatalog.pyEngine.Subgoal.search\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\GenerativeAI\\lib\\site-packages\\pyDatalog\\pyEngine.py:476\u001b[0m, in \u001b[0;36mpyDatalog.pyEngine.Literal.unify\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Miniconda\\envs\\GenerativeAI\\lib\\site-packages\\pyDatalog\\pyEngine.py:482\u001b[0m, in \u001b[0;36mpyDatalog.pyEngine.Literal.unify\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "user_id = 1\n",
    "products = recommend_products(user_id)\n",
    "ys = LikedByUser(user_id , Y)\n",
    "print(ys)\n",
    "print(products)\n",
    "print(\"Liked\")\n",
    "for y in ys:\n",
    "    Product(y[0] , X)\n",
    "    print(X)\n",
    "print(\"Reffered\")\n",
    "for y in products:\n",
    "    (Product(y , X))\n",
    "    print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recommended_products = recommend_products(user_id=1)\n",
    "# if recommended_products:\n",
    "#     for product_id in recommended_products:\n",
    "#         # Ensure the product_id exists in the DataFrame\n",
    "#         product_name = df[df['Product_Id'] == product_id]\n",
    "#         if not product_name.empty:\n",
    "#             print(f\"Recommended Product: {product_name['Product Name'].values[0]}\")\n",
    "#         else:\n",
    "#             print(f\"Product with ID {product_id} not found in the product list.\")\n",
    "# else:\n",
    "#     print(\"No recommendations found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyDatalog import pyDatalog\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Create terms\n",
    "pyDatalog.create_terms(\n",
    "    \"category, item, Smartphones, Laptops, Perfumes_and_Fragrances, Skincare, Food_Items, Home_Decor, Furniture, Women_s_Clothing, X, Y\"\n",
    ")\n",
    "\n",
    "+category('iPhone 9', 'Smartphones')\n",
    "+category('Samsung Universe 9', 'Smartphones')\n",
    "+category('OPPOF19', 'Smartphones')\n",
    "+category('Huawei P30', 'Smartphones')\n",
    "\n",
    "+category('MacBook Pro', 'Laptops')\n",
    "+category('Samsung Galaxy Book', 'Laptops')\n",
    "+category('Microsoft Surface Laptop 4', 'Laptops')\n",
    "+category('Infinix INBOOK', 'Laptops')\n",
    "+category('HP Pavilion 15-DK1056WM', 'Laptops')\n",
    "\n",
    "+category('perfume Oil', 'Perfumes_and_Fragrances')\n",
    "+category('Brown Perfume', 'Perfumes_and_Fragrances')\n",
    "+category('Fog Scent Xpressio Perfume', 'Perfumes_and_Fragrances')\n",
    "+category('Non-Alcoholic Concentrated Perfume Oil', 'Perfumes_and_Fragrances')\n",
    "+category('Eau De Perfume Spray', 'Perfumes_and_Fragrances')\n",
    "+category('Fog Scent Xpressio Perfume custom', 'Perfumes_and_Fragrances')\n",
    "\n",
    "+category('Hyaluronic Acid Serum', 'Skincare')\n",
    "+category('Tree Oil 30ml', 'Skincare')\n",
    "+category('Oil Free Moisturizer 100ml', 'Skincare')\n",
    "+category('Skin Beauty Serum.', 'Skincare')\n",
    "+category('Freckle Treatment Cream- 15gm', 'Skincare')\n",
    "\n",
    "+category('Daal Masoor 500 grams', 'Food_Items')\n",
    "+category('Elbow Macaroni - 400 gm', 'Food_Items')\n",
    "+category('Orange Essence Food Flavour', 'Food_Items')\n",
    "+category('Cereals muesli fruit nuts', 'Food_Items')\n",
    "+category('Gulab Powder 50 Gram', 'Food_Items')\n",
    "\n",
    "+category('Plant Hanger For Home', 'Home_Decor')\n",
    "+category('Flying Wooden Bird', 'Home_Decor')\n",
    "+category('3D Embellishment Art Lamp', 'Home_Decor')\n",
    "+category('Handcraft Chinese style', 'Home_Decor')\n",
    "+category('Key Holder', 'Home_Decor')\n",
    "\n",
    "+category('Mornadi Velvet Bed', 'Furniture')\n",
    "+category('Sofa for Coffee Cafe', 'Furniture')\n",
    "+category('3 Tier Corner Shelves', 'Furniture')\n",
    "+category('Plastic Table', 'Furniture')\n",
    "\n",
    "\n",
    "\n",
    "def read_json_to_dataframe(file_path):\n",
    "    \"\"\"\n",
    "    Reads a JSON file line by line, converts it to a DataFrame.\n",
    "    Args:\n",
    "        file_path (str): Path to the JSON file.\n",
    "    Returns:\n",
    "        pd.DataFrame: A pandas DataFrame containing the data.\n",
    "    \"\"\"\n",
    "    data = []  # List to store processed records\n",
    "\n",
    "    try:\n",
    "        # Open the file and load the JSON data\n",
    "        with open(file_path, 'r') as file:\n",
    "            json_data = json.load(file)\n",
    "\n",
    "        # Process the JSON data one by one\n",
    "        for record in json_data:\n",
    "            processed_record = {\n",
    "                \"_id\": record[\"_id\"],\n",
    "                \"title\": record[\"title\"],\n",
    "                \"description\": record[\"description\"],\n",
    "                \"price\": record[\"price\"],\n",
    "                \"discountPercentage\": record[\"discountPercentage\"],\n",
    "                \"stockQuantity\": record[\"stockQuantity\"],\n",
    "                \"brand\": record[\"brand\"],\n",
    "                \"category\": record[\"category\"],\n",
    "                \"thumbnail\": record[\"thumbnail\"],\n",
    "                \"images\": record[\"images\"],\n",
    "                \"isDeleted\": record[\"isDeleted\"],\n",
    "                \"updatedAt\": record[\"updatedAt\"]\n",
    "            }\n",
    "            data.append(processed_record)\n",
    "\n",
    "        # Convert the list of dictionaries into a pandas DataFrame\n",
    "        df = pd.DataFrame(data)\n",
    "        return df\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{file_path}' not found.\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Specify your JSON file path\n",
    "file_path = 'productdetails.json'\n",
    "\n",
    "# Call the function to read and convert the data\n",
    "df1 = read_json_to_dataframe(file_path)\n",
    "\n",
    "\n",
    "def display_category_products(product, df):\n",
    "    \"\"\"\n",
    "    Displays the details of products related to the given product\n",
    "    from DataFrame.\n",
    "    \"\"\"\n",
    "    # Get the category of the selected product\n",
    "    category_of_selected_item_result = category(product, Y)\n",
    "\n",
    "    if category_of_selected_item_result:\n",
    "        category_of_selected_item = category_of_selected_item_result[0]\n",
    "        related_products = category(X, category_of_selected_item[0])\n",
    "        related_product_names = [item[0] for item in related_products if item[0] != product] # Extract names except the selected product\n",
    "\n",
    "        # Filter df1 to only contain related product details\n",
    "        filtered_df = df[df['title'].isin(related_product_names)]\n",
    "        if not filtered_df.empty:\n",
    "          print(f\"Details of products related to '{product}':\")\n",
    "          print(filtered_df)\n",
    "        else:\n",
    "          print(f\"No details found for products related to '{product}'.\")\n",
    "    else:\n",
    "        print(f\"Product '{product}' not found in categories.\")\n",
    "\n",
    "product = \"iPhone 9\"\n",
    "# Example Usage\n",
    "display_category_products(product, df1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GenerativeAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
